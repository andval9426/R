library(dplyr)
library(ggplot2)
library(ggraph)
library(igraph)
library(readr)
library(dplyr)
library(ggplot2)
library(ggraph)
library(igraph)
library(readr)
library(litsearchr)
install_github("elizagrames/litsearchr", ref="main")
library(devtools)
# Instalar paquete ----
install_github("elizagrames/litsearchr", ref="main")
library(litsearchr)
library(dplyr)
library(ggplot2)
library(ggraph)
library(igraph)
library(readr)
library(devtools)
packageVersion("litsearchr")
# Cargar resultados ----
naive_results <- import_results(file="pubmed-medication-set.nbib")
# Cargar resultados ----
naive_results <- import_results(file="Datos/pubmed-medication-set.nbib")
View(naive_results)
library(easyPubMed)
# Cargar resultados a partir de APIs PUBMED
my_query <-  "(medication) AND (CBT) AND (phobia)"
my_entrez_id <- get_pubmed_ids(my_query)
my_abstracts_xml <- fetch_pubmed_data(pubmed_id_list = my_entrez_id)
my_titles <- custom_grep(my_abstracts_xml, "ArticleTitle", "char")
TTM <- nchar(my_titles) > 75
my_titles[TTM] <- paste(substr(my_titles[TTM], 1, 70), "...", sep = "")
head(my_titles,10)
# Cargar resultados a partir de APIs PUBMED
my_query <-  "medication AND CBT AND phobia"
my_entrez_id <- get_pubmed_ids(my_query)
my_abstracts_xml <- fetch_pubmed_data(pubmed_id_list = my_entrez_id)
my_titles <- custom_grep(my_abstracts_xml, "ArticleTitle", "char")
TTM <- nchar(my_titles) > 75
my_titles[TTM] <- paste(substr(my_titles[TTM], 1, 70), "...", sep = "")
head(my_titles,10)
my_titles
View(naive_results)
# Cargar resultados a partir de APIs PUBMED
my_query <-  "(medication) AND (CBT) AND (phobia)"
my_entrez_id <- get_pubmed_ids(my_query)
my_abstracts_xml <- fetch_pubmed_data(pubmed_id_list = my_entrez_id)
my_titles <- custom_grep(my_abstracts_xml, "ArticleTitle", "char")
TTM <- nchar(my_titles) > 75
my_titles[TTM] <- paste(substr(my_titles[TTM], 1, 70), "...", sep = "")
head(my_titles,10)
library(readr); library(devtools); library(easyPubMed); library(RISmed)
# 2. Cargar resultados a partir de APIs PUBMED
search_query <- EUtilsSummary(my_query, retmax=500)
summary(search_query)
QueryId(search_query)
records<- EUtilsGet(search_query)
# 2. Cargar resultados a partir de APIs PUBMED
search_query <- EUtilsSummary(my_query, retmax=500)
summary(search_query)
QueryId(search_query)
records<- EUtilsGet(search_query)
class(records)
pubmed_data <- data.frame('Title'=ArticleTitle(records),
'Abstract'=AbstractText(records))
head(pubmed_data,1)
D <- pmApiRequest(query = my_query, limit = 500, api_key = NULL)
# Funcion 3.
# -----------------------------------------------------------------------------------
library(pubmedR)
D <- pmApiRequest(query = my_query, limit = 500, api_key = NULL)
M <- pmApi2df(D)
M
M
D
my_query <-  "(medication) AND (CBT) AND (phobia)"
my_entrez_id <- get_pubmed_ids(my_query)
my_abstracts_xml <- fetch_pubmed_data(pubmed_id_list = my_entrez_id)
my_titles <- custom_grep(my_abstracts_xml, "ArticleTitle", "char")
TTM <- nchar(my_titles) > 75
my_titles[TTM] <- paste(substr(my_titles[TTM], 1, 70), "...", sep = "")
head(my_titles,10)
nrow(naive_results)
naive_results
colnames(naive_results)
naive_results[1, "title"]
naive_results[1, "keywords"]
naive_results[4, "keywords"]
naive_results[5, "keywords"]
sum(is.na(naive_results[, "keywords"]))
extract_terms(keywords=naive_results[, "keywords"], method="tagged")
?extract_terms
keywords <- extract_terms(keywords=naive_results[, "keywords"],
method="tagged", min_n=1)
keywords
extract_terms(text=naive_results[, "title"], method="fakerake", min_freq=3, min_n=2)
clinpsy_stopwords <- read_lines("Datos/palabras_vacias.txt")
clinpsy_stopwords
?read_lines
clinpsy_stopwords <- read.table("Datos/palabras_vacias.txt", header = TRUE)
clinpsy_stopwords
all_stopwords <- c(get_stopwords("English"), clinpsy_stopwords)
all_stopwords
title_terms <- extract_terms(
text=naive_results[, "title"],
method="fakerake",
min_freq=3, min_n=2,
stopwords=all_stopwords
)
title_terms
get_stopwords("English")
clinpsy_stopwords
class(clinpsy_stopwords$palabras_vacias)
clinpsy_stopwords <- read.table("Datos/palabras_vacias.txt", header = TRUE)
clinpsy_stopwords <- clinpsy_stopwords$palabras_vacias
clinpsy_stopwords
all_stopwords <- c(get_stopwords("English"), clinpsy_stopwords)
all_stopwords
title_terms <- extract_terms(
text=naive_results[, "title"],
method="fakerake",
min_freq=3, min_n=2,
stopwords=all_stopwords
)
title_terms
terms <- unique(c(keywords, title_terms))
terms
docs <- paste(naive_results[, "title"], naive_results[, "abstract"])
docs
docs[1]
dfm <- create_dfm(elements=docs, features=terms)
dfm
?create_dfm
g <- create_network(dfm, min_studies=3)
g
ggraph(g, layout="stress") +
coord_fixed() +
expand_limits(x=c(-3, 3)) +
geom_edge_link(aes(alpha=weight)) +
geom_node_point(shape="circle filled", fill="white") +
geom_node_text(aes(label=name), hjust="outward", check_overlap=TRUE) +
guides(edge_alpha=FALSE)
title_terms <- extract_terms(
text=naive_results[, "title"],
method="fakerake",
min_freq=3, min_n=2,
stopwords=all_stopwords
)
title_terms
# Cargar librerias ----
library(dplyr); library(ggplot2); library(ggraph); library(igraph)
library(readr); library(devtools); library(easyPubMed); library(RISmed)
# Cargar librerias ----
library(dplyr); library(ggplot2); library(ggraph); library(igraph)
library(readr); library(devtools); library(easyPubMed); library(RISmed)
# Instalar paquete ----
#install_github("elizagrames/litsearchr", ref="main")
library(litsearchr)
packageVersion("litsearchr")
# Cargar resultados ----
naive_results <- import_results(file="Datos/pubmed-medication-set.nbib")
# Explorando la busqueda realizada en PUBMED ----
nrow(naive_results) # numero de filas
colnames(naive_results) # nombres de las columnas
naive_results[5, "keywords"] # palabras claves fila 5
sum(is.na(naive_results[, "keywords"])) # numero de paper sin palabras claves
extract_terms(keywords=naive_results[, "keywords"],
method="tagged") # extraer palabras claves
# palabras claves
keywords <- extract_terms(keywords=naive_results[, "keywords"],
method="tagged", min_n=1)
# palabras vacias
clinpsy_stopwords <- read.table("Datos/palabras_vacias.txt", header = TRUE)
clinpsy_stopwords <- clinpsy_stopwords$palabras_vacias
# Union palabras vacias en ingles y las anteriores
all_stopwords <- c(get_stopwords("English"), clinpsy_stopwords)
# Extraer solo los términos de busqueda relevantes
title_terms <- extract_terms(
text=naive_results[, "title"],
method="fakerake",
min_freq=3, min_n=2,
stopwords=all_stopwords
)
title_terms
# Terminemos sumando los términos de búsqueda que obtuvimos de los títulos de
# los artículos y los que obtuvimos de las palabras clave anteriormente, eliminando
# los duplicados.
terms <- unique(c(keywords, title_terms))
terms
# Analisis de RED
docs <- paste(naive_results[, "title"], naive_results[, "abstract"])
# Analisis de RED
docs <- paste(naive_results[, "title"], naive_results[, "abstract"])
docs[1]
# Analisis de RED
docs <- paste(naive_results[, "title"], naive_results[, "abstract"])
docs[1]
dfm <- create_dfm(elements=docs, features=terms)
g <- create_network(dfm, min_studies=3)
ggraph(g, layout="stress") +
coord_fixed() +
expand_limits(x=c(-3, 3)) +
geom_edge_link(aes(alpha=weight)) +
geom_node_point(shape="circle filled", fill="white") +
geom_node_text(aes(label=name), hjust="outward", check_overlap=TRUE) +
guides(edge_alpha=FALSE)
dfm[1:3, 1:4]
g
# PODA ----
strengths <- strength(g)
strengths
data.frame(term=names(strengths), strength=strengths, row.names=NULL) %>%
mutate(rank=rank(strength, ties.method="min")) %>%
arrange(strength) ->
term_strengths
term_strengths
?rank
rank(strength, ties.method="min")
term_strengths
term_strengths
cutoff_fig <- ggplot(term_strengths,
aes(x=rank, y=strength, label=term)) +
geom_line() +
geom_point() +
geom_text(data=filter(term_strengths, rank>5), hjust="right", nudge_y=20, check_overlap=TRUE)
cutoff_fig
## Corte
cutoff_cum <- find_cutoff(g, method="cumulative", percent=0.8)
cutoff_cum
cutoff_fig +
geom_hline(yintercept=cutoff_cum, linetype="dashed")
cutoff_cum
get_keywords(reduce_graph(g, cutoff_cum))
# Puntos de cambio ----
cutoff_change <- find_cutoff(g, method="changepoint", knot_num=3)
cutoff_change
## Grafica
cutoff_fig +
geom_hline(yintercept=cutoff_change, linetype="dashed")
g_redux <- reduce_graph(g, cutoff_change[1])
selected_terms <- get_keywords(g_redux)
selected_terms
extra_terms <- c(
"medication",
"cognitive-behavioural therapy",
"cognitive behavioural therapy"
)
selected_terms <- c(selected_terms, extra_terms)
selected_terms
grouped_terms <-list(
medication=selected_terms[c(14, 28)],
cbt=selected_terms[c(4, 6, 7, 17, 24, 25, 26, 29, 30)],
phobia=selected_terms[c(2, 3, 9, 12, 15, 19, 20, 21, 23, 27)]
)
grouped_terms
write_search(
grouped_terms,
languages="English",
exactphrase=TRUE,
stemming=FALSE,
closure="left",
writesearch=TRUE
)
cat(read_file("search-inEnglish.txt"))
?read_file
